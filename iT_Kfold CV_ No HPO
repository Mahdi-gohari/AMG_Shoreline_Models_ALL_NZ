#iTransformer_Kfold CV_ No HPO
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppress TensorFlow INFO and WARNING logs
os.environ['CUDA_LOG_LEVEL'] = 'ERROR'    # Suppress CUDA warnings
os.environ['NV_LOG_LEVEL'] = 'ERROR'      # Suppress NVIDIA-specific logs

import logging
logging.getLogger('tensorflow').setLevel(logging.WARNING)  # Additional filter for TensorFlow

import tensorflow as tf
tf.debugging.set_log_device_placement(False)  # Disable device placement logs

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import random
import sys
from contextlib import contextmanager
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, MultiHeadAttention, Add, Layer, GaussianNoise
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback
from tensorflow.keras.regularizers import l2
from sklearn.model_selection import KFold

# Context manager to suppress TensorFlow output during specific computations
@contextmanager
def suppress_output():
    null_device = 'nul' if os.name == 'nt' else '/dev/null'
    with open(null_device, 'w') as null:
        stdout, stderr = sys.stdout, sys.stderr
        sys.stdout, sys.stderr = null, null
        try:
            yield
        finally:
            sys.stdout, sys.stderr = stdout, stderr

# Wave direction transformation
def transform_direction(theta):
    """Transforms wave direction (dpm) into a value between 0 and 1."""
    theta = np.array(theta) % 360
    psi = np.where(theta <= 180, 1 - theta / 180, (theta - 180) / 180)
    return psi

# Custom learning rate scheduler
class WarmUpCosineDecay(Callback):
    def __init__(self, initial_lr, warmup_epochs, total_epochs, steps_per_epoch):
        super(WarmUpCosineDecay, self).__init__()
        self.initial_lr = initial_lr
        self.warmup_epochs = warmup_epochs
        self.total_epochs = total_epochs
        self.steps_per_epoch = steps_per_epoch
        self.global_step = 0
        self.history = {}

    def on_batch_end(self, batch, logs=None):
        self.global_step += 1
        current_epoch = self.global_step // self.steps_per_epoch

        if current_epoch < self.warmup_epochs:
            lr = self.initial_lr * (self.global_step / (self.warmup_epochs * self.steps_per_epoch))
        else:
            progress = (self.global_step - self.warmup_epochs * self.steps_per_epoch) / \
                       ((self.total_epochs - self.warmup_epochs) * self.steps_per_epoch)
            lr = self.initial_lr * 0.5 * (1.0 + np.cos(np.pi * progress))

        self.model.optimizer.learning_rate.assign(lr)
        self.history.setdefault('lr', []).append(lr)

def set_seed(seed=42):
    np.random.seed(seed)
    random.seed(seed)
    tf.random.set_seed(seed)

set_seed(42)

# 1. Data Preparation
def load_and_preprocess_data(filepath):
    data = pd.read_csv(filepath, parse_dates=['dates'])

    data['days_since_start'] = (data['dates'] - data['dates'].min()).dt.days
    data['month'] = data['dates'].dt.month
    data["Hs_ma_7"] = data['Hs'].rolling(7).mean()
    data["Hs_ma_30"] = data['Hs'].rolling(30).mean()
    data["Tp_ma_7"] = data['Tp'].rolling(7).mean()
    data["Tp_ma_30"] = data['Tp'].rolling(30).mean()
    data["Dir_ma_7"] = data['Dir'].rolling(7).mean()
    data["Dir_ma_30"] = data['Dir'].rolling(30).mean()
    data["Eng_ma_7"] = data['Eng'].rolling(7).mean()
    data["Eng_ma_30"] = data['Eng'].rolling(30).mean()
    data['month_sin'] = np.sin(2 * np.pi * data['month'] / 12)
    data['month_cos'] = np.cos(2 * np.pi * data['month'] / 12)

    data = data.dropna()

    data['Dir_transformed'] = transform_direction(data['Dir'])

    data = data.dropna()

    train = data[data['dates'].dt.year <= 2020]
    test = data[data['dates'].dt.year > 2020]

    features = ['Hs', 'Tp', 'Eng', 'month_cos', 'month_sin', 'Dir_transformed']
    target = 'shore'

    scaler = StandardScaler()
    X_train = scaler.fit_transform(train[features])
    X_test = scaler.transform(test[features])

    y_scaler = StandardScaler()
    y_train = y_scaler.fit_transform(train[target].values.reshape(-1, 1)).flatten()
    y_test = y_scaler.transform(test[target].values.reshape(-1, 1)).flatten()

    train_dates = train['dates'].values
    test_dates = test['dates'].values

    return X_train, X_test, y_train, y_test, train_dates, test_dates, scaler, y_scaler

# 2. Create Sequences
def create_sequences(X, y, dates, window_size=90):
    X_seq, y_seq, date_seq = [], [], []
    for i in range(len(X) - window_size):
        X_seq.append(X[i:i+window_size])
        y_seq.append(y[i+window_size])
        date_seq.append(dates[i+window_size])
    return np.array(X_seq), np.array(y_seq), np.array(date_seq)

# Custom Layer for Transpose
class TransposeLayer(Layer):
    def __init__(self, perm, **kwargs):
        super(TransposeLayer, self).__init__(**kwargs)
        self.perm = perm

    def call(self, inputs):
        return tf.transpose(inputs, perm=self.perm)

    def get_config(self):
        config = super(TransposeLayer, self).get_config()
        config.update({"perm": self.perm})
        return config

# 3. iTransformer Model
def build_transformer(input_shape, num_heads=4, ff_dim=64, num_layers=2, dropout=0.3):
    inputs = Input(shape=input_shape)  # input_shape = (window_size, feature_dim)
    x = inputs

    # Add Gaussian noise for data augmentation
    x = GaussianNoise(stddev=0.1)(x, training=True)

    # Transpose to treat features as sequence: (batch, window_size, feature_dim) -> (batch, feature_dim, window_size)
    x = TransposeLayer(perm=[0, 2, 1])(x)

    # Positional Encoding for feature dimension
    def positional_encoding(length, d_model):
        pos = np.arange(length)[:, np.newaxis]
        i = np.arange(d_model)[np.newaxis, :]
        angle_rads = pos / np.power(10000, (2 * (i//2)) / np.float32(d_model))
        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])
        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])
        pos_encoding = angle_rads[np.newaxis, ...]
        return tf.cast(pos_encoding, dtype=tf.float32)

    pos_encoding = positional_encoding(input_shape[1], input_shape[0])  # Encode feature dimension
    x = x + pos_encoding

    # iTransformer Blocks
    for _ in range(num_layers):
        # Multi-Head Attention across features
        attention = MultiHeadAttention(num_heads=num_heads, key_dim=input_shape[0], dropout=0.3)(x, x)
        x = Add()([x, attention])
        x = LayerNormalization(epsilon=1e-6)(x)
        x = Dropout(dropout)(x)

        # Feed Forward Network
        ff = Dense(ff_dim, activation='relu', kernel_regularizer=l2(0.05))(x)
        ff = Dense(input_shape[0], kernel_regularizer=l2(0.05))(ff)  # Output dim matches window_size
        x = Add()([x, ff])
        x = LayerNormalization(epsilon=1e-6)(x)
        x = Dropout(dropout)(x)

    # Transpose back to original shape: (batch, feature_dim, window_size) -> (batch, window_size, feature_dim)
    x = TransposeLayer(perm=[0, 2, 1])(x)

    # Output Layers
    x = Flatten()(x)
    x = Dense(32, activation='relu', kernel_regularizer=l2(0.05))(x)
    x = Dropout(dropout)(x)
    outputs = Dense(1)(x)

    return Model(inputs, outputs)

# 4. Main Execution
def main():
    WINDOW_SIZE = 90
    EPOCHS = 200
    BATCH_SIZE = 256
    INITIAL_LR = 0.0005
    WARMUP_EPOCHS = 20
    K_FOLDS = 5

    print("Starting shoreline prediction model...")

    # Suppress logs during data loading and sequence creation
    with suppress_output():
        X_train, X_test, y_train, y_test, train_dates, test_dates, scaler, y_scaler = load_and_preprocess_data(
            'OTAMA_linear_smoothed.csv')
        print("Data loaded successfully.")  # Debug print (suppressed)

        X_train_seq, y_train_seq, train_date_seq = create_sequences(X_train, y_train, train_dates, WINDOW_SIZE)
        X_test_seq, y_test_seq, test_date_seq = create_sequences(X_test, y_test, test_dates, WINDOW_SIZE)

    # K-Fold Cross Validation
    kfold = KFold(n_splits=K_FOLDS, shuffle=False)
    fold_val_losses = []
    best_model = None
    best_val_loss = float('inf')

    for fold, (train_idx, val_idx) in enumerate(kfold.split(X_train_seq, y_train_seq)):
        print(f"\nTraining Fold {fold + 1}/{K_FOLDS}")
        X_train_fold = X_train_seq[train_idx]
        y_train_fold = y_train_seq[train_idx]
        X_val_fold = X_train_seq[val_idx]
        y_val_fold = y_train_seq[val_idx]

        # Suppress logs during model compilation
        with suppress_output():
            model = build_transformer((WINDOW_SIZE, X_train_seq.shape[2]))
            model.compile(optimizer=Adam(learning_rate=INITIAL_LR), loss='mse')

        early_stop = EarlyStopping(monitor='val_loss', patience=15, min_delta=0.0001, restore_best_weights=True)
        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=1)
        checkpoint = ModelCheckpoint(f'best_model_fold_{fold}.keras', monitor='val_loss', save_best_only=True, save_weights_only=False, verbose=0)  # Silent checkpoint
        warmup_lr = WarmUpCosineDecay(
            initial_lr=INITIAL_LR,
            warmup_epochs=WARMUP_EPOCHS,
            total_epochs=EPOCHS,
            steps_per_epoch=len(X_train_fold) // BATCH_SIZE
        )

        # Training logs visible with verbose=2
        history = model.fit(
            X_train_fold, y_train_fold,
            epochs=EPOCHS,
            batch_size=BATCH_SIZE,
            validation_data=(X_val_fold, y_val_fold),
            callbacks=[early_stop, reduce_lr, checkpoint, warmup_lr],
            verbose=2  # One line per epoch
        )

        val_loss = min(history.history['val_loss'])
        fold_val_losses.append(val_loss)

        if val_loss < best_val_loss:
            best_val_loss = val_loss
            best_model = tf.keras.models.load_model(f'best_model_fold_{fold}.keras', custom_objects={'TransposeLayer': TransposeLayer})

    # Suppress logs during prediction
    with suppress_output():
        train_pred = best_model.predict(X_train_seq)
        test_pred = best_model.predict(X_test_seq)

        # Inverse transform predictions
        train_pred = y_scaler.inverse_transform(train_pred).flatten()
        test_pred = y_scaler.inverse_transform(test_pred).flatten()

        y_train_seq = y_scaler.inverse_transform(y_train_seq.reshape(-1, 1)).flatten()
        y_test_seq = y_scaler.inverse_transform(y_test_seq.reshape(-1, 1)).flatten()

    # Print metrics
    print(f"\nAverage Validation Loss across {K_FOLDS} folds: {np.mean(fold_val_losses):.4f} ± {np.std(fold_val_losses):.4f}")
    print("\nEvaluation Metrics (Test):")
    print(f"Test MAE: {mean_absolute_error(y_test_seq, test_pred):.2f}")
    print(f"Test RMSE: {np.sqrt(mean_squared_error(y_test_seq, test_pred)):.2f}")
    print(f"Test R²: {r2_score(y_test_seq, test_pred):.2f}")

    # Plot training loss
    plt.figure(figsize=(10, 5))
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('Training and Validation Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)
    plt.savefig('training_loss1.png', dpi=300, bbox_inches='tight')
    plt.show()

    # Plot predictions
    plt.figure(figsize=(14, 6))
    plt.plot(train_date_seq, y_train_seq, label='Actual (Train)', color='blue', alpha=0.7)
    plt.plot(train_date_seq, train_pred, label='Predicted (Train)', color='cyan', linestyle='--')
    plt.plot(test_date_seq, y_test_seq, label='Actual (Test)', color='green', alpha=0.7)
    plt.plot(test_date_seq, test_pred, label='Predicted (Test)', color='red', linestyle='--')

    plt.title('Shoreline Position Prediction (1999-2025)')
    plt.xlabel('Year')
    plt.ylabel('Shoreline Position')
    plt.legend()
    plt.grid(True)
    plt.gca().xaxis.set_major_locator(mdates.YearLocator(4))
    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
    plt.gcf().autofmt_xdate()
    plt.savefig('shoreline_prediction1.png', dpi=300, bbox_inches='tight')
    plt.show()

    # Save results with three decimal places
    results = pd.DataFrame({
        'Date': np.concatenate([train_date_seq, test_date_seq]),
        'Actual': np.concatenate([y_train_seq, y_test_seq]),
        'Predicted': np.concatenate([train_pred, test_pred])
    })
    results.to_csv('prediction_OTAMA54.csv', index=False, float_format='%.3f')

if __name__ == "__main__":
    main()
